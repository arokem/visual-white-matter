{
 "metadata": {
  "name": "",
  "signature": "sha256:41afe691227df9d79c223ef30cbb6ef013dbcf5950898e506408976694a8e060"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Tractography : probabilistic tracking\n",
      "\n",
      "Considering that the information that we have in every voxel is not  \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import nibabel as nib\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "import dipy.core.gradients as grad\n",
      "from dipy.data import get_sphere\n",
      "from dipy.reconst.csdeconv import auto_response\n",
      "from dipy.reconst import sfm, dti\n",
      "from dipy.io.trackvis import save_trk\n",
      "from dipy.reconst.peaks import peaks_from_model\n",
      "from dipy.data import small_sphere\n",
      "from dipy.io.trackvis import save_trk\n",
      "from dipy.direction import ProbabilisticDirectionGetter\n",
      "from dipy.tracking.local import ThresholdTissueClassifier\n",
      "from dipy.tracking.local import LocalTracking\n",
      "\n",
      "from IPython.display import display, Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dwi_ni = nib.load('./data/SUB1_b2000_1.nii.gz')\n",
      "LV1_ni = nib.load('./data/LV1.nii.gz')\n",
      "labels_ni = nib.load('./data/aparc-reduced.nii.gz')\n",
      "\n",
      "data = dwi_ni.get_data()\n",
      "affine = dwi_ni.get_affine()\n",
      "\n",
      "LV1_data = LV1_ni.get_data()\n",
      "labels = labels_ni.get_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gtab = grad.gradient_table('./data/SUB1_b2000_1.bvals', './data/SUB1_b2000_1.bvecs')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "white_matter =  (labels == 1) | (labels == 2)\n",
      "V1 = (LV1_data == 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.7)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sphere = get_sphere()\n",
      "sf_model = sfm.SparseFascicleModel(gtab, sphere=sphere,\n",
      "                                   l1_ratio=0.5, alpha=0.001,\n",
      "                                   response=response[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We're going to fit the model in the entire white matter in the following cell, so this might take a little while to run:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf_fit = sf_model.fit(data, mask=white_matter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Probabilistic tracking requires a mechanism to sample directions from the distribution of directions provided by the model. \n",
      "\n",
      "In this case "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fodf = sf_fit.odf(small_sphere)\n",
      "prob_dg = ProbabilisticDirectionGetter.from_pmf(fodf, max_angle=30., sphere=small_sphere)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As in the determinstic tracking, we need an object that will terminate tracking based on tissue classification. Again, we will use the `TheresholdTissueClassifier` with FA>0.1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = ThresholdTissueClassifier(white_matter.astype(float), 0.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll seed the tracking at the pre-defined V1 ROI. We distribute plenty of seeds around V1: 8 in every voxel in the ROI, distributed as `[2, 2, 2]`, that is at a sampling rate of 2x2x2 in each voxel, along each dimension (x/y/z)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.ndimage as ndi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.unique(V1.astype(int))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our ROI resides in the gray matter, so we need to dilate it a little bit into the white matter. This gives as an ROI that contains not only gray matter voxels, but also the white-matter voxels that are adjacent to this part of cortex"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "V1_smoothed = ndi.gaussian_filter(V1.astype(float), sigma=0.25).astype(bool)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.where(V1_smoothed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.tracking import utils\n",
      "seeds = utils.seeds_from_mask(V1_smoothed, density=[2, 2, 2], affine=affine)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "streamlines = LocalTracking(prob_dg, classifier, seeds, affine, step_size=.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we are ready to perform the tracking itself. Tracking will be based on all the elements that we have defined so far. In the course of tracking, we will take steps of 0.5 mm. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len_th = 10\n",
      "\n",
      "streamlines = [s for s in streamlines if s.shape[0]>len_th]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(streamlines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.viz import fvtk\n",
      "from dipy.viz.colormap import line_colors\n",
      "from dipy.data import read_stanford_t1\n",
      "from dipy.tracking.utils import move_streamlines\n",
      "from numpy.linalg import inv\n",
      "t1 = read_stanford_t1()\n",
      "t1_data = t1.get_data()\n",
      "t1_aff = t1.get_affine()\n",
      "color = line_colors(streamlines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "streamlines_actor = fvtk.streamtube(\n",
      "                    list(move_streamlines(streamlines, inv(t1_aff))),\n",
      "                                    line_colors(streamlines))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vol_actor = fvtk.slicer(t1_data, voxsz=(1.0, 1.0, 1.0), plane_i=[40],\n",
      "                        plane_j=None, plane_k=[25], outline=False)\n",
      "\n",
      "ren = fvtk.ren()\n",
      "fvtk.add(ren, streamlines_actor)\n",
      "fvtk.add(ren, vol_actor)\n",
      "fvtk.camera(ren, viewup=(1,0,1), verbose=False)\n",
      "fvtk.record(ren, out_path='./prob-track.png', size=(600,600))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fvtk.show(ren)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(Image(filename='./prob-track.png'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_trk(\"prob-track.trk\", streamlines, affine, data.shape[:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}